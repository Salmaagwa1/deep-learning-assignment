{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_r2sluhgcDx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH = 32\n",
        "\n",
        "(ds_train, ds_test), info = tfds.load(\n",
        "    \"rock_paper_scissors\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "num_classes = info.features[\"label\"].num_classes\n",
        "print(\"classes:\", num_classes)\n",
        "\n",
        "# preprocessing\n",
        "def preprocess(img, label):\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "ds_train = (ds_train\n",
        "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .shuffle(1000)\n",
        "            .batch(BATCH)\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "ds_test = (ds_test\n",
        "           .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "           .batch(BATCH)\n",
        "           .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "base = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base.trainable = False  # Freeze\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = base(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history1 = model.fit(ds_train, validation_data=ds_test, epochs=5)"
      ],
      "metadata": {
        "id": "wx3_GQIAgiT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base.trainable = True\n",
        "\n",
        "for layer in base.layers[:-20]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "zFb0rKdPgiHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "N4uw_Laagh5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.2, patience=2, min_lr=1e-7\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "p-_pWtPYgh0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_test,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "wLEhUeQJghxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(ds_test)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "print(\"Test loss:\", test_loss)"
      ],
      "metadata": {
        "id": "WQnG77m9g2jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_true = np.concatenate([y for x, y in ds_test], axis=0)\n",
        "y_pred = np.argmax(model.predict(ds_test), axis=1)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "IaeniZ84g2gr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}